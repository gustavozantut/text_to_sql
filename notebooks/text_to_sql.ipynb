{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import string\n",
    "import psutil\n",
    "import json\n",
    "\n",
    "\n",
    "port = None\n",
    "fn_index = None\n",
    "\n",
    "#the server is http because speech to text js microphone needs http\n",
    "cert_path =  \"/appdata/RAG/trt-llm-rag-windows-ChatRTX_0.3/certs/servercert.pem\"\n",
    "key_path =  \"/appdata/RAG/trt-llm-rag-windows-ChatRTX_0.3/certs/serverkey.pem\"\n",
    "ca_bundle = \"/appdata/env_nvd_rag/Library/ssl/cacert.pem\"\n",
    "\n",
    "def find_chat_with_rtx_port():\n",
    "    global port\n",
    "    connections = psutil.net_connections(kind='inet')\n",
    "    for host in connections:\n",
    "        try:\n",
    "            if host.pid:\n",
    "                process = psutil.Process(host.pid)\n",
    "\n",
    "                if \"chatrtx\" in process.exe().lower():\n",
    "                    test_port = host.laddr.port\n",
    "                    url = f\"http://host.docker.internal:{test_port}/queue/join\"\n",
    "\n",
    "                    response = requests.post(url, data=\"\", timeout=0.1, cert=(cert_path, key_path), verify=ca_bundle)\n",
    "                    if response.status_code == 422:\n",
    "                        port = test_port\n",
    "                        return\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def join_queue(session_hash, set_fn_index, port, chatdata):\n",
    "    #fn_indexes are some gradio generated indexes from rag/trt/ui/user_interface.py\n",
    "    python_object = {\n",
    "        \"data\": chatdata,\n",
    "        \"event_data\": None,\n",
    "        \"fn_index\": set_fn_index,\n",
    "        \"session_hash\": session_hash\n",
    "    }\n",
    "    json_string = json.dumps(python_object)\n",
    "\n",
    "    url = f\"http://host.docker.internal:{port}/queue/join\"\n",
    "    response = requests.post(url, data=json_string, cert=(cert_path, key_path), verify=ca_bundle)\n",
    "    # print(\"Join Queue Response:\", response)\n",
    "\n",
    "def listen_for_updates(session_hash, port):\n",
    "    url = f\"http://host.docker.internal:{port}/queue/data?session_hash={session_hash}\"\n",
    "\n",
    "    response = requests.get(url, stream=True, cert=(cert_path, key_path), verify=ca_bundle)\n",
    "    # print(\"Listen Response:\", response)\n",
    "    try:\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                    data = json.loads(line[5:])\n",
    "                    # if data['msg'] == 'process_generating':\n",
    "                    #     print(data['output']['data'][0][0][1])\n",
    "                    if data['msg'] == 'process_completed':\n",
    "                        return data['output']['data'][0][0][1]\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "def auto_find_fn_index(port):\n",
    "    global fn_index\n",
    "\n",
    "    print(\"Searching for llm streamed completion function. Takes about 30 seconds.\")\n",
    "    session_hash = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n",
    "    chatdata = [[[\"write a comma\", None]], None]\n",
    "    for i in range(10, 1000):\n",
    "        join_queue(session_hash, i, port, chatdata)\n",
    "        res = listen_for_updates(session_hash, port)\n",
    "        if res:\n",
    "            fn_index = i\n",
    "            return\n",
    "    raise Exception(\"Failed to find fn_index\")\n",
    "\n",
    "def send_message(message, port=port):\n",
    "    global fn_index\n",
    "\n",
    "    if not port:\n",
    "        find_chat_with_rtx_port()\n",
    "    if not port:\n",
    "        raise Exception(\"Failed to find a server port for 'Chat with RTX'. Ensure the server is running.\")\n",
    "    if not fn_index:\n",
    "        #comment this line\n",
    "        auto_find_fn_index(port)\n",
    "        print(\"To make initialization instant hardcode:\\nfn_index =\", fn_index)\n",
    "        # fn_index = \n",
    "\n",
    "    session_hash = ''.join(random.choices(string.ascii_letters + string.digits, k=10))\n",
    "\n",
    "    chatdata = [[[message, None]], None]\n",
    "    join_queue(session_hash, fn_index, port, chatdata)\n",
    "    return listen_for_updates(session_hash, port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "import logging\n",
    "import sys\n",
    "from sqlalchemy.engine import URL\n",
    "from sqlalchemy import (\n",
    "    create_engine,\n",
    "    MetaData,\n",
    "    Table,\n",
    "    Column,\n",
    "    String,\n",
    "    Integer,\n",
    "    select,\n",
    "    text\n",
    ")\n",
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "from llama_index.core import SQLDatabase\n",
    "from llama_index.core.retrievers import NLSQLRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "server = 'host.docker.internal'\n",
    "database = 'llm_data'\n",
    "username = 'sa'\n",
    "password = 'Zantut123@'\n",
    "driver = '{ODBC Driver 18 for SQL Server}'\n",
    "\n",
    "# Connect to the SQL Server database\n",
    "conn_str = f'DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password};TrustServerCertificate=yes'\n",
    "connection_url = URL.create(\n",
    "    \"mssql+pyodbc\", \n",
    "    query={\"odbc_connect\": conn_str}\n",
    ")\n",
    "engine = create_engine(connection_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_metadata():\n",
    "    metadata_obj = MetaData()\n",
    "    metadata_obj.reflect(bind=engine)\n",
    "    return metadata_obj.tables\n",
    "\n",
    "def extract_query(sql_string):\n",
    "    \"\"\"\n",
    "    Extracts the first SELECT statement from a given SQL string until the first semicolon `;`.\n",
    "\n",
    "    Args:\n",
    "        sql_string (str): The SQL string.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted SELECT statement.\n",
    "    \"\"\"\n",
    "    # Find the index of the first occurrence of `SELECT`\n",
    "    select_index = sql_string.find('SELECT')\n",
    "    sc_index = sql_string.find(';')\n",
    "    select_query = sql_string[select_index:sc_index].replace('\\n',' ')\n",
    "\n",
    "    return select_query.strip()\n",
    "\n",
    "def query(response):\n",
    "    with engine.connect() as connection:\n",
    "        \n",
    "        result = connection.execute(text(response))\n",
    "\n",
    "        # Initialize an empty list to store the rows\n",
    "        rows_list = []\n",
    "\n",
    "        # Fetch all rows and append them to the list\n",
    "        for row in result.fetchall():\n",
    "            rows_list.append(row)\n",
    "\n",
    "    # The connection will be automatically closed after exiting the 'with' block\n",
    "\n",
    "    # Print the list of rows\n",
    "    return(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prefix_1='Dado o banco de dados: \\n '\n",
    "query_prefix_2='\\nForneça uma query para MSSQL que responda a seguinte pergunta: '\n",
    "query_prefix_3='Dada a pergunta: '\n",
    "query_prefix_4=' e com a seguinte resposta: \\n '\n",
    "query_suffix_1= '\\nuse CAST para operacoes, termine a query com ;'\n",
    "query_suffix_2=' forneca um texto de resposta estruturado. forneca apenas o texto, sem nada a mais'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PORT=41657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for llm streamed completion function. Takes about 30 seconds.\n",
      "To make initialization instant hardcode:\n",
      "fn_index = 86\n",
      "Response : Sim, eu posso ajudar com queries SQL. Por favor, dize-me o que precisas.\n"
     ]
    }
   ],
   "source": [
    "response = send_message(\"Ola! voce sabe sql poderia me ajudar com umas queries?\",port=PORT)\n",
    "print(\"Response :\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O texto de resposta estruturado seria:\n",
      "\n",
      "\"The total number of workers in the PNAD_TRIMESTRAL table is 1,391,785.\"\n",
      "A query utilizada foi a seguinte:\n",
      " SELECT SUM(CAST(vl_trabalhadores AS FLOAT)) AS total_workers FROM PNAD_TRIMESTRAL\n"
     ]
    }
   ],
   "source": [
    "query_str = \"qual a soma de trabalhadores?\"\n",
    "db_metadata = get_db_metadata()\n",
    "response = send_message(query_prefix_1+str(db_metadata).replace('FacadeDict','')+query_prefix_2+query_str+query_suffix_1,port=PORT)\n",
    "#print(response)\n",
    "query_str = extract_query(response)\n",
    "query_result=str(query(query_str))\n",
    "#print(query_result)\n",
    "response2 = send_message(query_prefix_3+query_str+query_prefix_4+query_result+query_suffix_2,port=PORT)\n",
    "print(response2)\n",
    "print('A query utilizada foi a seguinte:\\n',query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O resultado da consulta SQL \"SELECT MAX(CAST(temperature AS FLOAT)) AS max\\_temperature FROM dht11\\_room\\_temperature\" é:\n",
      "\n",
      "(34.0,)\n",
      "\n",
      "O valor máximo de temperatura registrado no banco de dados é 34.0.\n",
      "A query utilizada foi a seguinte:\n",
      " SELECT MAX(CAST(temperature AS FLOAT)) AS max_temperature FROM dht11_room_temperature\n"
     ]
    }
   ],
   "source": [
    "query_str = \"qual a maior temperatura registrada?\"\n",
    "db_metadata = get_db_metadata()\n",
    "response = send_message(query_prefix_1+str(db_metadata).replace('FacadeDict','')+query_prefix_2+query_str+query_suffix_1,port=PORT)\n",
    "#print(response)\n",
    "query_str = extract_query(response)\n",
    "query_result=str(query(query_str))\n",
    "#print(query_result)\n",
    "response2 = send_message(query_prefix_3+query_str+query_prefix_4+query_result+query_suffix_2,port=PORT)\n",
    "print(response2)\n",
    "print('A query utilizada foi a seguinte:\\n',query_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llama_index]",
   "language": "python",
   "name": "conda-env-llama_index-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
